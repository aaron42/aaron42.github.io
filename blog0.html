<h5>Found Papers:</h5>
<p>
Deep Learning for Video Game Playing <br>
Autoencoder-augmented neuroevolution for visual doom playing<br>
Combining strategic learning and tactical search in real-time strategy games<br>
The arcade learning environment: An evaluation platform for general agents<br>
Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures<br>
Playing doom with SLAM-augmented deep reinforcement learning<br>
Playing SNES in the retro learning environment<br>
Deep apprenticeship learning for playing video games<br>
Transfer deep reinforcement learning in 3D environments: An empirical study<br>
Intrinsically motivated reinforcement learning<br>
Deep reinforcement learning from human preferences<br>
Improving exploration in evolution strategies for deep reinforcement learning via a population of novelty-seeking agents<br>
Textworld: A learning environment for text-based games<br>
Playing atari with six neurons<br>
Model-free reinforcement learning with continuous action in practice<br>
Benchmarking deep reinforcement learning for continuous control<br>
Pathnet: Evolution channels gradient descent in super neural networks<br>
Learning visual predictive models of physics for playing billiards<br>
Machine learning in digital games: a survey<br>
Human-like playtesting with deep learning<br>
Deep learning for real-time atari game play using offline monte-carlo tree search planning<br>
Game engine learning from video<br>
Automatic content generation in the galactic arms race video game<br>
A neuroevolution approach to general atari game playing<br>
Believable Bots: Can Computers Play Like People?<br>
Continual online evolution for in-game build order adaptation in starcraft<br>
Learning macromanagement in StarCraft from replays using deep learning<br>
Multi-task learning in atari video games with emergent tangled program graphs<br>
Vizdoom: A doom-based ai research platform for visual reinforcement learning.<br>
General video game ai: Learning from screen capture.<br>
Playing FPS games with deep reinforcement learning<br>
Human-level control through deep reinforcement learning<br>
The combinatorial multi-armed bandit problem and its application to real-time strategy games<br>
Neurovisual control in the quake ii environment<br>
Deep reinforcement learning for general video game AI<br>
Tstarbots: Defeating the cheating level builtin ai in starcraft ii in the full game<br>
Torchcraft: a library for machine learning research on real-time strategy games<br>
A deep hierarchical approach to lifelong learning in minecraft<br>
Elf: An extensive, lightweight and flexible research platform for real-time strategy games<br>
Starcraft II: A new challenge for reinforcement learning<br>
</p>

<h5>Most Relevant Papers:</h5>
<p>
Deep Learning for Video Game Playing<br>
https://arxiv.org/abs/1708.07902<br>
This paper is a great overview of recent achievements of AIs playing video games. It serves as a catalog of the state-of-the-art researches of the field. it introduces the works that have been done in the different genres of the games, as well as the neural networks set-up actually used by the research.
</p>
<p>
Combining Strategic Learning and Tactical Search in Real-Time Strategy Games<br>
https://arxiv.org/abs/1709.03480<br>
This paper identifies the fact that tactics and strategies often don't coexist in AIs for real-time strategy games and try to use convolutional neural network to find the balance between them. The trained network is able to prodict the win rate of the games much more effectively.
</p>
<p>
Learning Macromanagement in StarCraft from Replays using Deep Learning<br>
https://arxiv.org/abs/1707.03743<br>
This paper tries to train a neural network that learns macromanagement from replays of highly-skilled players. As a result, UAlbertaBot using the strategy of the trained neural network can consistently beat itself using the simple rush strategy, showing the effectiveness of training through replays.
</p>
<p>
TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in the Full Game<br>
https://arxiv.org/format/1809.07193<br>
TStarBots, by adopting a hierarchical action modeling and rule based controllers, can consistently win against
the Starcraft II built-in AIs. This paper, according to its claim, has made the state-of-the-art reinforcement learning AI bots for Starcraft II, able to consistently defeat the high-difficulty cheating build-in AIs the game offers.
</p>
<p>
A Deep Hierarchical Approach to Lifelong Learning in Minecraft<br>
https://arxiv.org/abs/1604.07255<br>
This paper tries to use Hierarchical Deep Reinforcement Learning Network to allow the trained network to solve the lifelong learning problem in Minecraft. This means that the neural network needs to both be able to memorize the trained knowledge as skill, as well as select the appropriate skill based on time and space to solve the problem. The research tries to use Minecraft as a step toward truly general lifelong learning.
</p>


 


